{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# # Import PyDrive and associated libraries.\n",
    "# # This only needs to be done once per notebook.\n",
    "# # Documentation found here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# # Authenticate and create the PyDrive client.\n",
    "# # This only needs to be done once per notebook.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# # Link to data file stored in Drive: LINK TO YOUR CREDENTIALS FILE ON DRIVE\n",
    "# file_id = 'FILE_ID_OF_YOUR_CREDENTIALS_FILE_ON_DRIVE' # notice where this string comes from in link above\n",
    "\n",
    "# imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
    "# print(imported_file['title'])  # it should print the title of desired file\n",
    "# imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the encoded key from our credentials file\n",
    "from Twitter_credentials import auth_ready_key\n",
    "\n",
    "# include the requests library in order to get data from the web\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our `auth_ready_key` to a template `dict` object provided\n",
    "# in the Twitter API documentation\n",
    "auth_headers = {\n",
    " 'Authorization': 'Basic '+auth_ready_key,\n",
    " 'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'\n",
    "}\n",
    "\n",
    "# another `dict` describes what we're asking for\n",
    "auth_data = {\n",
    " 'grant_type': 'client_credentials'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our complete request to the authorization endpoint, and store\n",
    "# the results in the `auth_resp` variable\n",
    "auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)\n",
    "\n",
    "# pull the access token out of the json-formatted data\n",
    "# that the authorization endpoint sent back to us\n",
    "access_token = auth_resp.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have an access/bearer token, we're ready to request some data!\n",
    "# we'll create a new dict that includes this token\n",
    "search_headers = {\n",
    " 'Authorization': 'Bearer ' + access_token\n",
    "}\n",
    "\n",
    "# this is the Twitter search API endpoint for version 1.1 of the API\n",
    "search_url = 'https://api.twitter.com/1.1/search/tweets.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dict that includes our search query parameters\n",
    "search_params = {\n",
    " 'q': 'Python',\n",
    " 'result_type': 'recent',\n",
    " 'count': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send our data request and store the results in `search_resp`\n",
    "search_resp = requests.get(search_url, headers=search_headers, params=search_params)\n",
    "\n",
    "# parse the response into a JSON object\n",
    "Twitter_data = search_resp.json()\n",
    "\n",
    "# open an output file where we can save the results\n",
    "Twitter_output_file = open(\"Twitter_search_results.json\", \"w\")\n",
    "\n",
    "# write the returned Twitter data to our output file\n",
    "Twitter_output_file.write(str(Twitter_data))\n",
    "\n",
    "# close the output file\n",
    "Twitter_output_file.close()\n",
    "\n",
    "# loop through our results and print the text of the Twitter status\n",
    "for a_Tweet in Twitter_data['statuses']:\n",
    "    print(a_Tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# from google.colab import files\n",
    "\n",
    "# files.download(\"Twitter_search_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
